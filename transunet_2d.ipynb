{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3uernfiXfzU",
        "outputId": "43a48fd6-020b-4987-8642-96555a345e9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SRC: cloth3d++_subset/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.ndimage import binary_dilation, binary_erosion\n",
        "from skimage.transform import resize\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_unet_collection import models\n",
        "from tensorflow import keras\n",
        "from keras_unet_collection.utils import dummy_loader\n",
        "import cv2\n",
        "import gc\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.ndimage import binary_dilation, binary_erosion\n",
        "from skimage.transform import resize\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "# Path to data\n",
        "SRC = 'cloth3d++_subset/'\n",
        "print('SRC:', SRC)\n",
        "\n",
        "N_TRAIN = 128\n",
        "N_VAL = 16\n",
        "\n",
        "n_epochs = 50\n",
        "batch_size = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mvtrlRyHPhEO"
      },
      "outputs": [],
      "source": [
        "class TFRecordDataHandler:\n",
        "    def __init__(self, tfrecord_file, batch_size=32, shuffle=True, augment=False):\n",
        "        self.tfrecord_file = tfrecord_file\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "\n",
        "    def _parse_function(self, proto):\n",
        "        feature_description = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string),\n",
        "            'depth': tf.io.FixedLenFeature([], tf.string),\n",
        "            'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "            'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "            'depth_height': tf.io.FixedLenFeature([], tf.int64),\n",
        "            'depth_width': tf.io.FixedLenFeature([], tf.int64)\n",
        "        }\n",
        "        parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
        "\n",
        "        image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
        "        depth = tf.io.decode_raw(parsed_features['depth'], tf.float32)\n",
        "\n",
        "        height = parsed_features['height']\n",
        "        width = parsed_features['width']\n",
        "\n",
        "        image = tf.reshape(image, [height, width, 3])\n",
        "        depth = tf.reshape(depth, [parsed_features['depth_height'], parsed_features['depth_width']])\n",
        "\n",
        "        return image, depth\n",
        "\n",
        "    def _normalize(self, image, depth):\n",
        "        # Convert image to float for processing and normalize to range [0, 1]\n",
        "        image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "        # Create a mask where depth values are greater than zero\n",
        "        depth_mask = depth > 0\n",
        "\n",
        "        # Normalize depth based on masked regions\n",
        "        # Calculate the mean of the depth where it is greater than zero\n",
        "        depth_values = tf.boolean_mask(depth, depth_mask)\n",
        "        depth_mean = tf.reduce_mean(depth_values)\n",
        "\n",
        "        # Subtract the mean from the depth values where mask is true\n",
        "        depth = tf.where(depth_mask, depth - depth_mean, depth)\n",
        "\n",
        "        # Set depth values less than 0 to 0 after subtraction\n",
        "        depth = tf.maximum(depth, 0)\n",
        "\n",
        "        # Prepare the mask for RGB image normalization\n",
        "        mask = tf.tile(tf.expand_dims(depth_mask, axis=-1), [1, 1, 3])\n",
        "\n",
        "        # Masked image for mean and std deviation calculation\n",
        "        masked_image = tf.boolean_mask(image, mask)\n",
        "        mean, variance = tf.nn.moments(masked_image, axes=[0])\n",
        "        std_dev = tf.sqrt(variance + 1e-6)  # Adding epsilon to avoid division by zero\n",
        "\n",
        "        # Apply the mask to image normalization\n",
        "        normalized_image = tf.where(\n",
        "            mask,\n",
        "            (image - mean) / std_dev,\n",
        "            image  # Preserve original pixels where mask is False\n",
        "        )\n",
        "\n",
        "        return normalized_image, depth\n",
        "\n",
        "    def _augment(self, image, depth):\n",
        "        if tf.random.uniform(()) > 0.5:\n",
        "            image = tf.image.flip_left_right(image)\n",
        "            depth = tf.image.flip_left_right(tf.expand_dims(depth, axis=-1))\n",
        "            depth = tf.squeeze(depth, axis=-1)\n",
        "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "        return image, depth\n",
        "\n",
        "    def load_dataset(self):\n",
        "        dataset = tf.data.TFRecordDataset(self.tfrecord_file)\n",
        "        dataset = dataset.map(self._parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        dataset = dataset.map(self._normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "        if self.augment:\n",
        "            dataset = dataset.map(self._augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "        if self.shuffle:\n",
        "            dataset = dataset.shuffle(buffer_size=1000)\n",
        "\n",
        "        dataset = dataset.batch(self.batch_size)\n",
        "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "        return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VqMXIYooQ42i"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LearningRateLogger(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        lr = self.model.optimizer.lr\n",
        "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "            lr = lr(self.model.optimizer.iterations)\n",
        "        print(f\"Epoch {epoch + 1}: Learning rate is {tf.keras.backend.get_value(lr):.6f}\")\n",
        "\n",
        "class TensorBoardLearningRateLogger(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, log_dir='./logs'):\n",
        "        super(TensorBoardLearningRateLogger, self).__init__()\n",
        "        self.file_writer = tf.summary.create_file_writer(log_dir)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        lr = self.model.optimizer.lr\n",
        "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "            lr = lr(self.model.optimizer.iterations)\n",
        "        with self.file_writer.as_default():\n",
        "            tf.summary.scalar('learning_rate', tf.keras.backend.get_value(lr), step=epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YAZZ0Q1aWPnt"
      },
      "outputs": [],
      "source": [
        "def visualize_hist(history, show=True, filename=None, title='Training history'):\n",
        "    train_hist = history.history\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 4))\n",
        "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
        "\n",
        "    ax1.plot(train_hist['loss'])\n",
        "    ax1.plot(train_hist['val_loss'])\n",
        "    ax1.set(xlabel='epoch', ylabel='Loss')\n",
        "    ax1.legend(['train', 'valid'], loc='upper right')\n",
        "\n",
        "    ax2.plot(train_hist['mae'])\n",
        "    ax2.plot(train_hist['val_mae'])\n",
        "    ax2.set(xlabel='epoch', ylabel='MAE')\n",
        "    ax2.legend(['train', 'valid'], loc='upper right')\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "\n",
        "    if filename is not None:\n",
        "        fig.savefig(filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Lv-hK_godkrl"
      },
      "outputs": [],
      "source": [
        "class WarmUpCosineDecayScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, initial_learning_rate, target_learning_rate, total_steps, warmup_steps):\n",
        "        super(WarmUpCosineDecayScheduler, self).__init__()\n",
        "        self.initial_learning_rate = initial_learning_rate\n",
        "        self.target_learning_rate = target_learning_rate\n",
        "        self.total_steps = total_steps\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.decay_steps = total_steps - warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        # Convert to float32 to ensure the operations are compatible\n",
        "        step = tf.cast(step, tf.float32)\n",
        "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
        "        decay_steps = tf.cast(self.decay_steps, tf.float32)\n",
        "\n",
        "        # Compute the warmup learning rate\n",
        "        warmup_lr = self.initial_learning_rate + (self.target_learning_rate - self.initial_learning_rate) * (step / warmup_steps)\n",
        "\n",
        "        # Compute the cosine decay learning rate\n",
        "        cosine_decay = 0.5 * (1 + tf.cos(np.pi * (step - warmup_steps) / decay_steps))\n",
        "        decayed_lr = (self.target_learning_rate - self.initial_learning_rate) * cosine_decay + self.initial_learning_rate\n",
        "\n",
        "        # Choose the learning rate based on the step\n",
        "        learning_rate = tf.where(step < warmup_steps, warmup_lr, decayed_lr)\n",
        "        return learning_rate\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            'initial_learning_rate': self.initial_learning_rate,\n",
        "            'target_learning_rate': self.target_learning_rate,\n",
        "            'total_steps': self.total_steps,\n",
        "            'warmup_steps': self.warmup_steps\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uYYTcSsWQRw",
        "outputId": "8c2396d7-92c8-43bf-a9b9-79c2b6b519c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of data used to train:\n",
            "372\n",
            "\n",
            "Input shape: (4, 256, 256, 3)\n",
            "Label shape: (4, 256, 256)\n",
            "Learning rate: 1e-05\n",
            "Epoch 1/50\n",
            "93/93 [==============================] - 80s 670ms/step - loss: 0.0646 - mae: 0.1922 - val_loss: 0.9081 - val_mae: 0.9399\n",
            "Epoch 2/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0157 - mae: 0.0787 - val_loss: 0.0269 - val_mae: 0.0637\n",
            "Epoch 3/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0087 - mae: 0.0486 - val_loss: 0.0212 - val_mae: 0.0553\n",
            "Epoch 4/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0081 - mae: 0.0433 - val_loss: 0.0247 - val_mae: 0.0565\n",
            "Epoch 5/50\n",
            "93/93 [==============================] - 61s 654ms/step - loss: 0.0070 - mae: 0.0373 - val_loss: 0.0106 - val_mae: 0.0399\n",
            "Epoch 6/50\n",
            "93/93 [==============================] - 61s 657ms/step - loss: 0.0067 - mae: 0.0342 - val_loss: 0.0094 - val_mae: 0.0383\n",
            "Epoch 7/50\n",
            "93/93 [==============================] - 61s 654ms/step - loss: 0.0067 - mae: 0.0341 - val_loss: 0.0083 - val_mae: 0.0347\n",
            "Epoch 8/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0065 - mae: 0.0327 - val_loss: 0.0093 - val_mae: 0.0380\n",
            "Epoch 9/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0063 - mae: 0.0316 - val_loss: 0.0085 - val_mae: 0.0353\n",
            "Epoch 10/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0060 - mae: 0.0301 - val_loss: 0.0096 - val_mae: 0.0360\n",
            "Epoch 11/50\n",
            "93/93 [==============================] - 61s 654ms/step - loss: 0.0058 - mae: 0.0294 - val_loss: 0.0084 - val_mae: 0.0332\n",
            "Epoch 12/50\n",
            "93/93 [==============================] - 61s 657ms/step - loss: 0.0056 - mae: 0.0286 - val_loss: 0.0088 - val_mae: 0.0332\n",
            "Epoch 13/50\n",
            "93/93 [==============================] - 61s 657ms/step - loss: 0.0062 - mae: 0.0309 - val_loss: 0.0092 - val_mae: 0.0360\n",
            "Epoch 14/50\n",
            "93/93 [==============================] - 61s 658ms/step - loss: 0.0056 - mae: 0.0284 - val_loss: 0.3332 - val_mae: 0.3840\n",
            "Epoch 15/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0058 - mae: 0.0286 - val_loss: 0.0080 - val_mae: 0.0378\n",
            "Epoch 16/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0061 - mae: 0.0293 - val_loss: 0.0085 - val_mae: 0.0346\n",
            "Epoch 17/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0057 - mae: 0.0282 - val_loss: 0.0091 - val_mae: 0.0347\n",
            "Epoch 18/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0055 - mae: 0.0274 - val_loss: 0.0079 - val_mae: 0.0377\n",
            "Epoch 19/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0054 - mae: 0.0268 - val_loss: 0.0086 - val_mae: 0.0326\n",
            "Epoch 20/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0053 - mae: 0.0262 - val_loss: 0.0076 - val_mae: 0.0326\n",
            "Epoch 21/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0050 - mae: 0.0253 - val_loss: 0.0074 - val_mae: 0.0303\n",
            "Epoch 22/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0051 - mae: 0.0254 - val_loss: 0.0079 - val_mae: 0.0315\n",
            "Epoch 23/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0049 - mae: 0.0251 - val_loss: 0.0074 - val_mae: 0.0316\n",
            "Epoch 24/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0050 - mae: 0.0250 - val_loss: 0.0068 - val_mae: 0.0295\n",
            "Epoch 25/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0047 - mae: 0.0239 - val_loss: 0.0067 - val_mae: 0.0287\n",
            "Epoch 26/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0047 - mae: 0.0240 - val_loss: 0.0067 - val_mae: 0.0277\n",
            "Epoch 27/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0046 - mae: 0.0237 - val_loss: 0.0074 - val_mae: 0.0288\n",
            "Epoch 28/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0047 - mae: 0.0239 - val_loss: 0.0068 - val_mae: 0.0282\n",
            "Epoch 29/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0047 - mae: 0.0239 - val_loss: 0.0065 - val_mae: 0.0282\n",
            "Epoch 30/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0049 - mae: 0.0250 - val_loss: 0.0079 - val_mae: 0.0315\n",
            "Epoch 31/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0051 - mae: 0.0254 - val_loss: 0.0068 - val_mae: 0.0274\n",
            "Epoch 32/50\n",
            "93/93 [==============================] - 61s 657ms/step - loss: 0.0047 - mae: 0.0244 - val_loss: 0.0076 - val_mae: 0.0298\n",
            "Epoch 33/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 0.0061 - val_mae: 0.0264\n",
            "Epoch 34/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0045 - mae: 0.0231 - val_loss: 0.0075 - val_mae: 0.0294\n",
            "Epoch 35/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 0.0060 - val_mae: 0.0260\n",
            "Epoch 36/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0042 - mae: 0.0223 - val_loss: 0.0060 - val_mae: 0.0256\n",
            "Epoch 37/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0042 - mae: 0.0222 - val_loss: 0.0061 - val_mae: 0.0264\n",
            "Epoch 38/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0041 - mae: 0.0220 - val_loss: 0.0060 - val_mae: 0.0257\n",
            "Epoch 39/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0041 - mae: 0.0219 - val_loss: 0.0099 - val_mae: 0.0368\n",
            "Epoch 40/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0051 - mae: 0.0248 - val_loss: 0.0068 - val_mae: 0.0281\n",
            "Epoch 41/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0046 - mae: 0.0234 - val_loss: 0.0064 - val_mae: 0.0268\n",
            "Epoch 42/50\n",
            "93/93 [==============================] - 61s 654ms/step - loss: 0.0045 - mae: 0.0228 - val_loss: 0.0064 - val_mae: 0.0271\n",
            "Epoch 43/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0043 - mae: 0.0225 - val_loss: 0.0063 - val_mae: 0.0267\n",
            "Epoch 44/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0043 - mae: 0.0223 - val_loss: 0.0068 - val_mae: 0.0276\n",
            "Epoch 45/50\n",
            "93/93 [==============================] - 61s 658ms/step - loss: 0.0042 - mae: 0.0221 - val_loss: 0.0061 - val_mae: 0.0261\n",
            "Epoch 46/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0042 - mae: 0.0220 - val_loss: 0.0060 - val_mae: 0.0259\n",
            "Epoch 47/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0040 - mae: 0.0214 - val_loss: 0.0058 - val_mae: 0.0253\n",
            "Epoch 48/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0040 - mae: 0.0214 - val_loss: 0.0060 - val_mae: 0.0258\n",
            "Epoch 49/50\n",
            "93/93 [==============================] - 61s 656ms/step - loss: 0.0040 - mae: 0.0212 - val_loss: 0.0059 - val_mae: 0.0254\n",
            "Epoch 50/50\n",
            "93/93 [==============================] - 61s 655ms/step - loss: 0.0038 - mae: 0.0208 - val_loss: 0.0058 - val_mae: 0.0253\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best validation loss: 0.005832240916788578 at epoch 49\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "initial_learning_rate = 1e-5\n",
        "target_learning_rate = 1e-2\n",
        "verbose = 1\n",
        "shuffle = True\n",
        "checkpoint = './best_model.h5'\n",
        "\n",
        "\n",
        "\n",
        "train_dg = TFRecordDataHandler('train.tfrecords', batch_size=batch_size, shuffle=shuffle, augment=True).load_dataset()\n",
        "validation_dg = TFRecordDataHandler('validation.tfrecords', batch_size=batch_size, shuffle=shuffle, augment=False).load_dataset()\n",
        "print('Number of data used to train:')\n",
        "print(len(list(train_dg))* batch_size)\n",
        "print('')\n",
        "\n",
        "for x, y in train_dg.take(1):\n",
        "    print(\"Input shape:\", x.shape)  # Should be (batch_size, height, width, channels)\n",
        "    print(\"Label shape:\", y.shape)  # Should be (batch_size, ...) depending on your task\n",
        "\n",
        "\n",
        "total_steps = len(list(train_dg)) * n_epochs\n",
        "\n",
        "\n",
        "for wu_ratio in [0.1]:\n",
        "\n",
        "    warmup_steps = int(wu_ratio * total_steps)\n",
        "\n",
        "    experiment_name = f'lr_decay_{initial_learning_rate}_{target_learning_rate}_wu_ratio_{wu_ratio}_transunet_2d_bs_{batch_size}'\n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=os.path.join('./logs_TransUnet', experiment_name))\n",
        "\n",
        "\n",
        "    # Create the learning rate schedule\n",
        "    lr_schedule = WarmUpCosineDecayScheduler(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        target_learning_rate=target_learning_rate,\n",
        "        total_steps=total_steps,\n",
        "        warmup_steps=warmup_steps\n",
        "    )\n",
        "\n",
        "    # Define the optimizer with the custom learning rate schedule\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "\n",
        "    model = models.transunet_2d((256, 256, 3), [64, 128, 256, 512, 1024], n_labels=1,\n",
        "                            stack_num_down=2, stack_num_up=1,\n",
        "                            activation='GELU', output_activation='Sigmoid',\n",
        "                            batch_norm=True, pool='max', unpool=False, name='transunet_2d', embed_dim=100, num_heads=4)\n",
        "\n",
        "    print('Learning rate:', initial_learning_rate)\n",
        "    # defining the optimizer\n",
        "    model.compile(optimizer, loss=tf.keras.losses.MeanSquaredError(), metrics=['mae'])\n",
        "\n",
        "    # es = tf.keras.callbacks.EarlyStopping(monitor='val_mae', patience=3)\n",
        "\n",
        "    # saving the best model based on val_loss\n",
        "    # mc = tf.keras.callbacks.ModelCheckpoint(checkpoint, monitor='val_mae', mode='min', save_best_only=True, save_freq=5)\n",
        "\n",
        "    # training the model and saving the history\n",
        "    history = model.fit(train_dg, validation_data=validation_dg, epochs=n_epochs, verbose=verbose, workers=4, use_multiprocessing=True,\n",
        "                        callbacks=[tensorboard_callback])\n",
        "\n",
        "    # Plot and write the history\n",
        "    if not os.path.exists(experiment_name):\n",
        "        os.makedirs(experiment_name)\n",
        "    filename = os.path.join(experiment_name, 'train_history.jpg')\n",
        "    visualize_hist(history, show=True, filename=filename)\n",
        "\n",
        "    #with open('train_history_lr_'+str(lr)+'.pkl', 'wb') as handle:\n",
        "    #    pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    # Get the best validation loss and the epoch\n",
        "\n",
        "    best_val_loss = min(history.history['val_loss'])\n",
        "    best_epoch = history.history['val_loss'].index(best_val_loss)\n",
        "    # d_lr[lr] = (best_val_loss, best_epoch)\n",
        "    print('Best validation loss:', best_val_loss, 'at epoch', best_epoch)\n",
        "\n",
        "    # Clear gpu memory\n",
        "    del model\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of data used to train:\n",
            "372\n",
            "\n",
            "Input shape: (4, 256, 256, 3)\n",
            "Label shape: (4, 256, 256)\n",
            "Learning rate: 1e-05\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node 'transunet_2d_model/transunet_2d_ViT_6_mlp_dense_1/Tensordot/MatMul' defined at (most recent call last):\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\xavie\\AppData\\Local\\Temp\\ipykernel_27528\\1070447381.py\", line 61, in <module>\n      history = model.fit(train_dg, validation_data=validation_dg, epochs=n_epochs, verbose=verbose, workers=2, use_multiprocessing=True,\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 244, in call\n      outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\nNode: 'transunet_2d_model/transunet_2d_ViT_6_mlp_dense_1/Tensordot/MatMul'\nOOM when allocating tensor with shape[1024,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node transunet_2d_model/transunet_2d_ViT_6_mlp_dense_1/Tensordot/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_68210]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 61\u001b[0m\n\u001b[0;32m     53\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer, loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# es = tf.keras.callbacks.EarlyStopping(monitor='val_mae', patience=3)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# saving the best model based on val_loss\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# mc = tf.keras.callbacks.ModelCheckpoint(checkpoint, monitor='val_mae', mode='min', save_best_only=True, save_freq=5)\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# training the model and saving the history\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Plot and write the history\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(experiment_name):\n",
            "File \u001b[1;32mc:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'transunet_2d_model/transunet_2d_ViT_6_mlp_dense_1/Tensordot/MatMul' defined at (most recent call last):\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\xavie\\AppData\\Local\\Temp\\ipykernel_27528\\1070447381.py\", line 61, in <module>\n      history = model.fit(train_dg, validation_data=validation_dg, epochs=n_epochs, verbose=verbose, workers=2, use_multiprocessing=True,\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\xavie\\miniconda3\\envs\\or\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 244, in call\n      outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\nNode: 'transunet_2d_model/transunet_2d_ViT_6_mlp_dense_1/Tensordot/MatMul'\nOOM when allocating tensor with shape[1024,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node transunet_2d_model/transunet_2d_ViT_6_mlp_dense_1/Tensordot/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_68210]"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "initial_learning_rate = 1e-5\n",
        "target_learning_rate = 1e-2\n",
        "verbose = 1\n",
        "shuffle = True\n",
        "checkpoint = './best_model.h5'\n",
        "\n",
        "\n",
        "\n",
        "train_dg = TFRecordDataHandler('train.tfrecords', batch_size=batch_size, shuffle=shuffle, augment=True).load_dataset()\n",
        "validation_dg = TFRecordDataHandler('validation.tfrecords', batch_size=batch_size, shuffle=shuffle, augment=False).load_dataset()\n",
        "print('Number of data used to train:')\n",
        "print(len(list(train_dg))* batch_size)\n",
        "print('')\n",
        "\n",
        "for x, y in train_dg.take(1):\n",
        "    print(\"Input shape:\", x.shape)  # Should be (batch_size, height, width, channels)\n",
        "    print(\"Label shape:\", y.shape)  # Should be (batch_size, ...) depending on your task\n",
        "\n",
        "\n",
        "total_steps = len(list(train_dg)) * n_epochs\n",
        "\n",
        "\n",
        "for wu_ratio in [0.1]:\n",
        "\n",
        "    warmup_steps = int(wu_ratio * total_steps)\n",
        "\n",
        "    experiment_name = f'/lr_decay_{initial_learning_rate}_{target_learning_rate}_wu_ratio_{wu_ratio}_transunet_2d_max_embed_dim'\n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=os.path.join(experiment_name, 'TensorBoard'))\n",
        "    tensorboard_lr_logger = TensorBoardLearningRateLogger(os.path.join(experiment_name, 'TensorBoard'))\n",
        "\n",
        "\n",
        "    # Create the learning rate schedule\n",
        "    lr_schedule = WarmUpCosineDecayScheduler(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        target_learning_rate=target_learning_rate,\n",
        "        total_steps=total_steps,\n",
        "        warmup_steps=warmup_steps\n",
        "    )\n",
        "\n",
        "    # Define the optimizer with the custom learning rate schedule\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "\n",
        "    model = models.transunet_2d((256, 256, 3), [64, 128, 256, 512, 1024], n_labels=1,\n",
        "                            stack_num_down=2, stack_num_up=1,\n",
        "                            activation='GELU', output_activation='Sigmoid',\n",
        "                            batch_norm=True, pool='max', unpool=False, name='transunet_2d', num_heads=4)\n",
        "\n",
        "    print('Learning rate:', initial_learning_rate)\n",
        "    # defining the optimizer\n",
        "    model.compile(optimizer, loss=tf.keras.losses.MeanSquaredError(), metrics=['mae'])\n",
        "\n",
        "    # es = tf.keras.callbacks.EarlyStopping(monitor='val_mae', patience=3)\n",
        "\n",
        "    # saving the best model based on val_loss\n",
        "    # mc = tf.keras.callbacks.ModelCheckpoint(checkpoint, monitor='val_mae', mode='min', save_best_only=True, save_freq=5)\n",
        "\n",
        "    # training the model and saving the history\n",
        "    history = model.fit(train_dg, validation_data=validation_dg, epochs=n_epochs, verbose=verbose, workers=2, use_multiprocessing=True,\n",
        "callbacks=[tensorboard_callback]\n",
        "                        )\n",
        "\n",
        "    # Plot and write the history\n",
        "    if not os.path.exists(experiment_name):\n",
        "        os.makedirs(experiment_name)\n",
        "    filename = os.path.join(experiment_name, 'train_history.jpg')\n",
        "    visualize_hist(history, show=True, filename=filename)\n",
        "\n",
        "    #with open('train_history_lr_'+str(lr)+'.pkl', 'wb') as handle:\n",
        "    #    pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    # Get the best validation loss and the epoch\n",
        "\n",
        "    best_val_loss = min(history.history['val_loss'])\n",
        "    best_epoch = history.history['val_loss'].index(best_val_loss)\n",
        "    # d_lr[lr] = (best_val_loss, best_epoch)\n",
        "    print('Best validation loss:', best_val_loss, 'at epoch', best_epoch)\n",
        "\n",
        "    # Clear gpu memory\n",
        "    del model\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
